{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('C:/Users/Richard Teller/Desktop/429/Project/Data/train.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine                                        ingredients\n",
       "0        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian                [water, vegetable oil, wheat, salt]\n",
       "4       indian  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['id'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lime, mung beans, sesame oil, peanut butter, carrots, fish sauce, fresh ginger, green onions, cilantro, garlic cloves, monterey jack, honey, hoisin sauce, red pepper, pizza doughs, boiling water, soy sauce, Sriracha, cooked chicken, rice vinegar, oyster sauce',\n",
       " 'eggs, decorating sugars, softened butter, white sugar, ground cinnamon, milk, salt, confectioners sugar, melted butter, active dry yeast, all-purpose flour, sour cream, warm water, vanilla extract, chopped pecans',\n",
       " 'olive oil, crushed red pepper, tomatoes, kalamata, dried oregano, sun-dried tomatoes, onions, capers, garlic',\n",
       " 'butter, spinach leaves, salt, rainbow trout, heavy cream, fennel, freshly ground pepper',\n",
       " 'chicken stock, veal, all-purpose flour, dried porcini mushrooms, large garlic cloves, onions, marsala wine, fresh thyme, ground allspice, dried thyme, button mushrooms',\n",
       " 'red chili peppers, lemon grass, cumin seed, fresh ginger, paprika, lime, shallots, coriander seeds, garlic',\n",
       " 'kale, coriander, green olives, ground beef, avocado, yams, cumin, green bell pepper, onions',\n",
       " 'fish sauce, lime juice, soy sauce, peanut oil, brown sugar, garlic, fresh red chili, white wine, large shrimp',\n",
       " 'pepper, chopped fresh mint, grape leaves, salt, ground lamb, water, long grain white rice, pinenuts, onions',\n",
       " 'lean ground beef, taco seasoning, diced tomatoes, wonton wrappers, sharp cheddar cheese']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = df['ingredients'].tolist()\n",
    "y = df['cuisine'].tolist()\n",
    "\n",
    "# In order to use the text vectorization stuff, we need X_train to be a list, in \n",
    "# format of [\"ingr1, ingr2\", \"ingr1, ingr2, ingr3\"] where basically each recipe is just a sentence\n",
    "# with ingredients seperated by a comma.  The following for loop does this, by using a method from String\n",
    "# that joins the strings in a list, into one string seperated by the specified string, in this case I used\n",
    "# ', '\n",
    "\n",
    "new_X = []\n",
    "for l in X:\n",
    "    new_X.append(', '.join(l))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=.2, random_state=20)\n",
    "X_train[:10] # X_train is a list, this is how you print the first 10 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# Now that we have our train test split, we can start vectorizing our documents (recipes).\n",
    "\n",
    "# Tfidf is recommended for short documents (I think).  Our documents are short since they contain around 20\n",
    "# words or so for a single recipe at max\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)  # Creates a matrix that represents the counts of each word\n",
    "                                                    # where the index represents a word, and the value there\n",
    "                                                    # is the count of that word in the document.\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()  # I don't know what this does, I might be doing something redundant here\n",
    "                                        # All I know is it performs better if you use the transformer\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB().fit(X_train_tfidf, y_train) # Don't ask why I used Multinomial Naive Bayes\n",
    "                                                    # I was following a tutorial-ish \n",
    "                                                    # http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6862350722815839"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This also works, don't need tfidf_transformer\n",
    "# However, it gets 2% less accuracy\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X_train_counts = vectorizer.fit_transform(X_train)\n",
    "# model = MultinomialNB().fit(X_train_counts, y_train)\n",
    "# X_test_counts = vectorizer.transform(X_test)\n",
    "# y_pred = model.predict(X_test_counts)\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
