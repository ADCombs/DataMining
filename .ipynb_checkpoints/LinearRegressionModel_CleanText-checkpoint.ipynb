{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download nltk (even if it comes with Acaconda) and tell python what the path is, otherwise we can't use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to ./nltk_data/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Eli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"wordnet\", \"./nltk_data/\")\n",
    "nltk.data.path.append('./nltk_data/')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll clean the data by removing any punctuation, converting the ingredients to lower case using Lemmatization, removing stop words and removing non-ascii characters.\n",
    "After doing this however, I'm not sure how to convert ingredients_string back to a type that the code below can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce, black olives, grape tomatoes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour, ground pepper, salt, tomato, grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>egg, pepper, salt, mayonaise, cooking oil, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water, vegetable oil, wheat, salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper, shallot, cornflour, cayenne pepp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                  ingredients_string  \n",
       "0  romaine lettuce, black olives, grape tomatoes,...  \n",
       "1  plain flour, ground pepper, salt, tomato, grou...  \n",
       "2  egg, pepper, salt, mayonaise, cooking oil, gre...  \n",
       "3                  water, vegetable oil, wheat, salt  \n",
       "4  black pepper, shallot, cornflour, cayenne pepp...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import printable\n",
    "st = set(printable)\n",
    "\n",
    "df = pd.read_json(\"./train.json\")\n",
    "\n",
    "df['ingredients_string'] = [', '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in df['ingredients']]\n",
    "#df['ingredients_string'] = df['ingredients_string'].str.replace('[{}]'.format('!\"#$%;&\\'()*+-./:<=>?@[\\\\]^_`{|}~'), ',')\n",
    "#df['ingredients_string'] = df['ingredients_string'].str.lower()\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "df['ingredients_string'] = df['ingredients_string'].str.replace(pat, '')\n",
    "df['ingredients_string'] = df['ingredients_string'].str.replace(r'\\s+', ' ')\n",
    "df[\"ingredients_string\"] = df[\"ingredients_string\"].apply(lambda x: ''.join([\" \" if  i not in  st else i for i in x]))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = df['ingredients_string'].tolist()\n",
    "y = df['cuisine'].tolist()\n",
    "\n",
    "#new_X = []\n",
    "#for l in X:\n",
    "#    new_X.append(', '.join(l))\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)  \n",
    "\n",
    "tfidf_transformer = TfidfTransformer() \n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(df.cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train_tfidf, y_train) \n",
    "\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "y_pred = logistic.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.774732872407291"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
